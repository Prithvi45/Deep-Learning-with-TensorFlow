{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Convolution ?\n",
    "\n",
    "* g(x,y) = h(x,y)*f(x,y)\n",
    "\n",
    "* Convolution can achieve something,  that the previous two methods of manipulating images can’t achieve. Those include the blurring, sharpening, edge detection, noise reduction e.t.c.\n",
    "\n",
    "### Applications in Image Processing\n",
    "* Blurring, line and edge detections\n",
    "* Sobel method, gaussian, laplacian masks are available to achieve this\n",
    "\n",
    "## Formulae\n",
    "* Definition of 1D Convolution : y[n]=x[n]*h[n] = summ(x[n].h[n-k])    k-> -inifinite to infinite\n",
    "\n",
    "\n",
    "#### Learn all deep learning layer apis of tensorflow  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.array([6,2])\n",
    "h = np.array([1,2,5,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.convolve(x,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3])\n",
    "b = np.array([5,6,7])\n",
    "c = np.convolve(a,b)\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply convolution on  1D array and 2D image  using TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process\n",
    "* Convolution ->  relu(activation) --> pooling -> relu(activation)  -> Dropouts -> Probability conversion(softmax)\n",
    "* Relu Activation function : used to handle non linear data\n",
    "* Relu is used for Normalization\n",
    "* Relu fires 0 for all negative values\n",
    "* pooling-> picks max value from applied patch on array\n",
    "* backpropogation -> Gradient Descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch = tf.constant([\n",
    "        [  # First Image\n",
    "            [[0, 255, 0], [0, 255, 0], [0, 255, 0]],\n",
    "            [[0, 255, 0], [0, 255, 0], [0, 255, 0]]\n",
    "        ],\n",
    "        [  # Second Image\n",
    "            [[0, 0, 255], [0, 0, 255], [0, 0, 255]],\n",
    "            [[0, 0, 255], [0, 0, 255], [0, 0, 255]]\n",
    "        ]\n",
    "    ])\n",
    "image_batch.get_shape()\n",
    "\n",
    "#below dimensions are as -> rows of image 1, rows of image 2 , columns, color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_batch = tf.constant([\n",
    "        [  # First Input\n",
    "            [[0.0], [1.0]],\n",
    "            [[2.0], [3.0]]\n",
    "        ],\n",
    "        [  # Second Input\n",
    "            [[2.0], [4.0]],\n",
    "            [[6.0], [8.0]]\n",
    "        ]\n",
    "    ])\n",
    "\n",
    "kernel = tf.constant([\n",
    "        [\n",
    "            [[1.0, 2.0]]\n",
    "        ]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv2d = tf.nn.conv2d(input_batch, kernel, strides=[1, 1, 1, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(conv2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_right_image_pixel = sess.run(input_batch)[0][1][1]\n",
    "lower_right_kernel_pixel = sess.run(conv2d)[0][1][1]\n",
    "lower_right_image_pixel, lower_right_kernel_pixel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strides\n",
    "The value of convolutions in computer vision is their ability to reduce the dimensionality of the input, which is an image in this case. An image’s dimensionality (2D image) is its width, height and number of channels. A large image dimensionality requires an exponentially larger amount of time for a neural network to scan over every pixel and judge which ones are important. Reducing dimensionality of an image with convolutions is done by altering the strides of the kernel.\n",
    "\n",
    "The parameter strides, causes a kernel to skip over pixels of an image and not include them in the output. It’s not fair to say the pixels are skipped because they still may affect the output. The strides parameter highlights how a convolution operation is working with a kernel when a larger image and more complex kernel are used. As a convolution is sliding the kernel over the input, it’s using the strides parameter to change how it walks over the input. Instead of going over every element of an input, the strides parameter could configure the convolution to skip certain elements.\n",
    "\n",
    "For example, take the convolution of a larger image and a larger kernel. In this case, it’s a convolution between a 6 pixel tall, 6 pixel wide and 1 channel deep image (6x6x1) and a (3x3x1) kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch = tf.constant([\n",
    "        [  # First Input (6x6x1)\n",
    "            [[0.0], [1.0], [2.0], [3.0], [4.0], [5.0]],\n",
    "            [[0.1], [1.1], [2.1], [3.1], [4.1], [5.1]],\n",
    "            [[0.2], [1.2], [2.2], [3.2], [4.2], [5.2]],\n",
    "            [[0.3], [1.3], [2.3], [3.3], [4.3], [5.3]],\n",
    "            [[0.4], [1.4], [2.4], [3.4], [4.4], [5.4]],\n",
    "            [[0.5], [1.5], [2.5], [3.5], [4.5], [5.5]],\n",
    "        ],\n",
    "    ])\n",
    "\n",
    "kernel = tf.constant([  # Kernel (3x3x1)\n",
    "        [[[0.0]], [[0.5]], [[0.0]]],\n",
    "        [[[0.0]], [[1.0]], [[0.0]]],\n",
    "        [[[0.0]], [[0.5]], [[0.0]]]\n",
    "    ])\n",
    "\n",
    "# NOTE: the change in the size of the strides parameter.\n",
    "conv2d = tf.nn.conv2d(input_batch, kernel, strides=[1, 3, 3, 1], padding='SAME')\n",
    "sess.run(conv2d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding\n",
    "When a kernel is overlapped on an image it should be set to fit within the bounds of the image. At times, the sizing may not fit and a good alternative is to fill the missing area in the image. Filling the missing area of the image is known as padding the image. TensorFlow will pad the image with zeros or raise an error when the sizes don’t allow a kernel to stride over an image without going past its bounds. The amount of zeros or the error state of tf.nn.conv2d is controlled by the parameter padding which has two possible values ('VALID', ‘SAME').\n",
    "\n",
    "SAME: The convolution output is the SAME size as the input. This doesn’t take the filter’s size into account when calculating how to stride over the image. This may stride over more of the image than what exists in the bounds while padding all the missing values with zero.\n",
    "\n",
    "VALID: Take the filter’s size into account when calculating how to stride over the image. This will try to keep as much of the kernel inside the image’s bounds as possible. There may be padding in some cases but will avoid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge Detection example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kernel = tf.constant([\n",
    "        [\n",
    "            [[ -1., 0., 0.], [ 0., -1., 0.], [ 0., 0., -1.]],\n",
    "            [[ -1., 0., 0.], [ 0., -1., 0.], [ 0., 0., -1.]],\n",
    "            [[ -1., 0., 0.], [ 0., -1., 0.], [ 0., 0., -1.]]\n",
    "        ],\n",
    "        [\n",
    "            [[ -1., 0., 0.], [ 0., -1., 0.], [ 0., 0., -1.]],\n",
    "            [[ 8., 0., 0.], [ 0., 8., 0.], [ 0., 0., 8.]],\n",
    "            [[ -1., 0., 0.], [ 0., -1., 0.], [ 0., 0., -1.]]\n",
    "        ],\n",
    "        [\n",
    "            [[ -1., 0., 0.], [ 0., -1., 0.], [ 0., 0., -1.]],\n",
    "            [[ -1., 0., 0.], [ 0., -1., 0.], [ 0., 0., -1.]],\n",
    "            [[ -1., 0., 0.], [ 0., -1., 0.], [ 0., 0., -1.]]\n",
    "        ]\n",
    "    ], )\n",
    "\n",
    "image_batch = tf.cast(image_batch, tf.float32)\n",
    "conv2d = tf.nn.conv2d(image_batch, kernel, [1, 1, 1, 1], padding=\"SAME\")\n",
    "activation_map = sess.run(tf.minimum(tf.nn.relu(conv2d), 255))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output created from convolving an image with an edge detection kernel are all the areas where and edge was detected. The code assumes a batch of images is already available (image_batch) with a real image loaded from disk. In this case, the image is an example image found in the Stanford Dogs Dataset. The kernel has three input and three output channels. The channels sync up to RGB values between left-bracket 0 comma 255 right-bracket with 255 being the maximum intensity. The tf.minimum and tf.nn.relu calls are there to keep the convolution values within the range of valid RGB colors of left-bracket 0 comma 255 right-bracket.\n",
    "\n",
    "\n",
    "There are many other) common kernels which can be used in this simplified example. Each will highlight different patterns in an image with different results. The following kernel will sharpen an image by increasing the intensity of color changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kernel = tf.constant([\n",
    "        [\n",
    "            [[ 0., 0., 0.], [ 0., 0., 0.], [ 0., 0., 0.]],\n",
    "            [[ -1., 0., 0.], [ 0., -1., 0.], [ 0., 0., -1.]],\n",
    "            [[ 0., 0., 0.], [ 0., 0., 0.], [ 0., 0., 0.]]\n",
    "        ],\n",
    "        [\n",
    "            [[ -1., 0., 0.], [ 0., -1., 0.], [ 0., 0., -1.]],\n",
    "            [[ 5., 0., 0.], [ 0., 5., 0.], [ 0., 0., 5.]],\n",
    "            [[ -1., 0., 0.], [ 0., -1., 0.], [ 0., 0., -1.]]\n",
    "        ],\n",
    "        [\n",
    "            [[ 0., 0., 0.], [ 0., 0., 0.], [ 0., 0., 0.]],\n",
    "            [[ -1., 0., 0.], [ 0., -1., 0.], [ 0., 0., -1.]],\n",
    "            [[ 0, 0., 0.], [ 0., 0., 0.], [ 0., 0., 0.]]\n",
    "        ]\n",
    "    ])\n",
    "\n",
    "image_batch = tf.cast(image_batch, tf.float32)\n",
    "conv2d = tf.nn.conv2d(image_batch, kernel, [1, 1, 1, 1], padding=\"SAME\")\n",
    "activation_map = sess.run(tf.minimum(tf.nn.relu(conv2d), 255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow()\n",
    "activation_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Layers\n",
    "For a neural network architecture to be considered a CNN, it requires at least one convolution layer (tf.nn.conv2d). There are practical uses for a single layer CNN (edge detection), for image recognition and categorization it is common to use different layer types to support a convolution layer. These layers help reduce over-fitting, speed up training and decrease memory usage.\n",
    "\n",
    "The layers covered in this chapter are focused on layers commonly used in a CNN architecture. A CNN isn’t limited to use only these layers, they can be mixed with layers designed for other network architectures.\n",
    "\n",
    "\n",
    "\n",
    "### Convolution Layers\n",
    "One type of convolution layer has been covered in detail (tf.nn.conv2d) but there are a few notes which are useful to advanced users. The convolution layers in TensorFlow don’t do a full convolution, details can be found in the TensorFlow API documentation. In practice, the difference between a convolution and the operation TensorFlow uses is performance. TensorFlow uses a technique to speed up the convolution operation in all the different types of convolution layers.\n",
    "There are use cases for each type of convolution layer but for tf.nn.conv2d is a good place to start. The other types of convolutions are useful but not required in building a network capable of object recognition and classification. A brief summary of each is included.\n",
    "\n",
    "TF.NN.DEPTHWISE_CONV2D\n",
    "This convolution is used when attaching the output of one convolution to the input of another convolution layer. An advanced use case is using a tf.nn.depthwise_conv2d to create a network following the inception architecture.\n",
    "\n",
    "TF.NN.SEPARABLE_CONV2D\n",
    "This is similar to tf.nn.conv2d, but not a replacement for it. For large models, it speeds up training without sacrificing accuracy. For small models, it will converge quickly with worse accuracy.\n",
    "\n",
    "TF.NN.CONV2D_TRANSPOSE\n",
    "This applies a kernel to a new feature map where each section is filled with the same values as the kernel. As the kernel strides over the new image, any overlapping sections are summed together. There is a great explanation on how tf.nn.conv2d_transpose is used for learnable upsampling in Stanford’s CS231n Winter 2016: Lecture 13."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Activation Functions\n",
    "These functions are used in combination with the output of other layers to generate a feature map. They’re used to smooth (or differentiate) the results of certain operations. The goal is to introduce non-linearity into the neural network. Non-linearity means that the input is a curve instead of a straight line. Curves are capable of representing more complex changes in input. For example, non-linear input is capable of describing input which stays small for the majority of the time but periodically has a single point at an extreme. Introduction of non-linearity in a neural network allows it to train on the complex patterns found in data.\n",
    "\n",
    "TensorFlow has multiple activation functions available. With CNNs, tf.nn.relu is primarily used because of its performance although it sacrifices information. When starting out, using tf.nn.relu is recommended but advanced users may create their own. When considering if an activation function is useful there are a few primary considerations.\n",
    "\n",
    "1. The function is monotonic, so its output should always be increasing or decreasing along with the input. This allows gradient descent optimization to search for local minima.\n",
    "\n",
    "2. The function is differentiable, so there must be a derivative at any point in the function’s domain. This allows gradient descent optimization to properly work using the output from this style of activation function.\n",
    "\n",
    "Any functions that satisfy those considerations could be used as activation functions. In TensorFlow there are a few worth highlighting which are common to see in CNN architectures. A brief summary of each is included with a small sample code illustrating their usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF.NN.RELU\n",
    "A rectifier (rectified linear unit) called a ramp function in some documentation and looks like a skateboard ramp when plotted. ReLU is linear and keeps the same input values for any positive numbers while setting all negative numbers to be 0. It has the benefits that it doesn’t suffer from gradient vanishing and has a range of left-bracket 0 comma plus normal infinity right-parenthesis. A drawback of ReLU is that it can suffer from neurons becoming saturated when too high of a learning rate is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tf.range(-2, 3)\n",
    "relu_out = tf.nn.relu(features)\n",
    "# Keep note of the value for negative features\n",
    "sess.run([features, relu_out])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF.SIGMOID\n",
    "A sigmoid function returns a value in the range of left-bracket 0.0 comma 1.0 right-bracket. Larger values sent into a tf.sigmoid will trend closer to 1.0 while smaller values will trend towards 0.0. The ability for sigmoids to keep a values between left-bracket 0.0 comma 1.0 right-bracket is useful in networks which train on probabilities which are in the range of  left-bracket 0.0 comma 1.0 right-bracket. The reduced range of output values can cause trouble with input becoming saturated and changes in input becoming exaggerated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note, tf.sigmoid (tf.nn.sigmoid) is currently limited to float values\n",
    "features = tf.to_float(tf.range(-1, 3))\n",
    "sess.run([features, tf.sigmoid(features)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF.TANH\n",
    "\n",
    "A hyperbolic tangent function (tanh) is a close relative to tf.sigmoid with some of the same benefits and drawbacks. The main difference between tf.sigmoid and tf.tanh is that tf.tanh has a range of left-bracket negative 1.0 comma 1.0 right-bracket. The ability to output negative values may be useful in certain network architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note, tf.tanh (tf.nn.tanh) is currently limited to float values\n",
    "features = tf.to_float(tf.range(-1, 3))\n",
    "sess.run([features, tf.tanh(features)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF.NN.DROPOUT\n",
    "Set the output to be 0.0 based on a configurable probability. This layer performs well in scenarios where a little randomness helps training. An example scenario is when there are patterns being learned that are too tied to their neighboring features. This layer will add a little noise to the output being learned.\n",
    "\n",
    "NOTE: This layer should only be used during training because the random noise it adds will give misleading results while testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tf.constant([-0.1, 0.0, 0.1, 0.2])\n",
    "# Note, the output should be different on almost ever execution. Your numbers won't match\n",
    "# this output.\n",
    "sess.run([features, tf.nn.dropout(features, keep_prob=0.5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the output has a 50% probability of being kept. Each execution of this layer will have different output (most likely, it’s somewhat random). When an output is dropped, its value is set to 0.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling Layers\n",
    "Pooling layers reduce over-fitting and improving performance by reducing the size of the input. They’re used to scale down input while keeping important information for the next layer. It’s possible to reduce the size of the input using a tf.nn.conv2d alone but these layers execute much faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF.NN.MAX_POOL\n",
    "Strides over a tensor and chooses the maximum value found within a certain kernel size. Useful when the intensity of the input data is relevant to importance in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usually the input would be output from a previous layer and not an image directly.\n",
    "# Our task is to find largest valus from the array\n",
    "batch_size=1\n",
    "input_height = 3\n",
    "input_width = 3\n",
    "input_channels = 1\n",
    "\n",
    "layer_input = tf.constant([\n",
    "        [\n",
    "            [[1.0], [0.2], [1.5]],\n",
    "            [[0.1], [1.2], [1.4]],\n",
    "            [[1.1], [0.4], [0.4]]\n",
    "        ]\n",
    "    ])\n",
    "\n",
    "# The strides will look at the entire input by using the image_height and image_width\n",
    "kernel = [batch_size, input_height, input_width, input_channels]\n",
    "max_pool = tf.nn.max_pool(layer_input, kernel, [1, 1, 1, 1], \"VALID\")\n",
    "sess.run(max_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_input.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The layer_input is a tensor with a shape similar to the output of tf.nn.conv2d or an activation function. The goal is to keep only one value, the largest value in the tensor. In this case, the largest value of the tensor is 1.5 and is returned in the same format as the input. If the kernel were set to be smaller, it would choose the largest value in each kernel size as it strides over the image.\n",
    "\n",
    "Max-pooling will commonly be done using 2x2 receptive field (kernel with a height of 2 and width of 2) which is often written as a “2x2 max-pooling operation”. One reason to use a 2x2 receptive field is that it’s the smallest amount of downsampling which can be done in a single pass. If a 1x1 receptive field were used then the output would be the same as the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF.NN.AVG_POOL\n",
    "Strides over a tensor and averages all the values at each depth found within a kernel size. Useful when reducing values where the entire kernel is important, for example, input tensors with a large width and height but small depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1\n",
    "input_height = 3\n",
    "input_width = 3\n",
    "input_channels = 1\n",
    "\n",
    "layer_input = tf.constant([\n",
    "        [\n",
    "            [[1.0], [1.0], [1.0]],\n",
    "            [[1.0], [0.5], [0.0]],\n",
    "            [[0.0], [0.0], [0.0]]\n",
    "        ]\n",
    "    ])\n",
    "\n",
    "# The strides will look at the entire input by using the image_height and image_width\n",
    "kernel = [batch_size, input_height, input_width, input_channels]\n",
    "max_pool = tf.nn.avg_pool(layer_input, kernel, [1, 1, 1, 1], \"VALID\")\n",
    "sess.run(max_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "Normalization layers are not unique to CNNs and aren’t used as often. When using tf.nn.relu, it is useful to consider normalization of the output. Since ReLU is unbounded, it’s often useful to utilize some form of normalization to identify high-frequency features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF.NN.LOCAL_RESPONSE_NORMALIZATION (TF.NN.LRN)\n",
    "Local response normalization is a function which shapes the output based on a summation operation best explained in TensorFlow’s documentation.\n",
    "\n",
    "... Within a given vector, each component is divided by the weighted, squared sum of inputs within depth_radius.\n",
    "\n",
    "One goal of normalization is to keep the input in a range of acceptable numbers. For instance, normalizing input in the range of left-bracket 0.0 comma 1.0 right-bracket where the full range of possible values is normalized to be represented by a number greater than or equal to 0.0 and less than or equal to 1.0. Local response normalization normalizes values while taking into account the significance of each value.\n",
    "\n",
    "Cuda-Convnet includes further details on why using local response normalization is useful in some CNN architectures. ImageNet uses this layer to normalize the output from tf.nn.relu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a range of 3 floats.\n",
    "# [0,1]\n",
    "#  TensorShape([batch, image_height, image_width, image_channels])\n",
    "layer_input = tf.constant([\n",
    "        [[[ 1.]], [[ 2.]], [[ 3.]]]\n",
    "    ])\n",
    "\n",
    "lrn = tf.nn.local_response_normalization(layer_input)\n",
    "sess.run([layer_input, lrn])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High Level Layers\n",
    "TensorFlow has introduced high level layers designed to make it easier to create fairly standard layer definitions. These aren’t required to use but they help avoid duplicate code while following best practices. While getting started, these layers add a number of non-essential nodes to the graph. It’s worth waiting until the basics are comfortable before using these layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF.CONTRIB.LAYERS.CONVOLUTION2D\n",
    "The convolution2d layer will do the same logic as tf.nn.conv2d while including weight initialization, bias initialization, trainable variable output, bias addition and adding an activation function. Many of these steps haven’t been covered for CNNs yet but should be familiar. A kernel is a trainable variable (the CNN’s goal is to train this variable), weight initialization is used to fill the kernel with values (tf.truncated_normal) on its first run. The rest of the parameters are similar to what have been used before except they are reduced to short-hand version. Instead of declaring the full kernel, now it’s a simple tuple (1,1) for the kernel’s height and width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_input = tf.constant([\n",
    "            [\n",
    "                [[0., 0., 0.], [255., 255., 255.], [254., 0., 0.]],\n",
    "                [[0., 191., 0.], [3., 108., 233.], [0., 191., 0.]],\n",
    "                [[254., 0., 0.], [255., 255., 255.], [0., 0., 0.]]\n",
    "            ]\n",
    "        ])\n",
    "\n",
    "conv2d = tf.contrib.layers.convolution2d(\n",
    "    image_input,\n",
    "#     num_output_channels=4,     this is deprecated , use below one\n",
    "    num_outputs=4,\n",
    "    kernel_size=(1,1),          # It's only the filter height and width.\n",
    "    activation_fn=tf.nn.relu,\n",
    "    stride=(1, 1),              # Skips the stride values for image_batch and input_channels.\n",
    "    trainable=True)\n",
    "\n",
    "# It's required to initialize the variables used in convolution2d's setup.\n",
    "# sess.run(tf.initialize_all_variables())   derecated , use below function\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(conv2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: tf.to_float should not be used if the input is an image, instead use tf.image.convert_image_dtype which will properly change the range of values used to describe colors. In this example code, float values of 255. were used which aren’t what TensorFlow expects when is sees an image using float values. TensorFlow expects an image with colors described as floats to stay in the range of left-bracket 0 comma 1 right-bracket."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  TF.CONTRIB.LAYERS.FULLY_CONNECTED\n",
    "A fully connected layer is one where every input is connected to every output. This is a fairly common layer in many architectures but for CNNs, the last layer is quite often fully connected. The tf.contrib.layers.fully_connected layer offers a great short-hand to create this last layer while following best practices.\n",
    "\n",
    "Typical fully connected layers in TensorFlow are often in the format of tf.matmul(features, weight) + bias where feature, weight and bias are all tensors. This short-hand layer will do the same thing while taking care of the intricacies involved in managing the weight and bias tensors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tf.constant([\n",
    "        [[1.2], [3.4]]\n",
    "    ])\n",
    "\n",
    "fc = tf.contrib.layers.fully_connected(features, num_outputs=2)\n",
    "\n",
    "# It's required to initialize all the variables first or there'll be an error about precondition failures.\n",
    "# sess.run(tf.initialize_all_variables())\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images and TensorFlow\n",
    "TensorFlow is designed to support working with images as input to neural networks. TensorFlow supports loading common file formats (JPG, PNG), working in different color spaces (RGB, RGBA) and common image manipulation tasks. TensorFlow makes it easier to work with images but it’s still a challenge. The largest challenge working with images are the size of the tensor which is eventually loaded. Every image requires a tensor the same size as the image’s h e i g h t asterisk w i d t h asterisk c h a n n e l s (h.w.c) . As a reminder, channels are represented as a rank 1 tensor including a scalar amount of color in each channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A red RGB pixel in TensorFlow would be represented with the following tensor.\n",
    "red = tf.constant([255, 0, 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The match_filenames_once will accept a regex but there is no need for this example.\n",
    "image_filename = \"prithvi.png\"\n",
    "filename_queue = tf.train.string_input_producer(\n",
    "    tf.train.match_filenames_once(image_filename))\n",
    "\n",
    "image_reader = tf.WholeFileReader()\n",
    "_, image_file = image_reader.read(filename_queue)\n",
    "image = tf.image.decode_jpeg(image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
