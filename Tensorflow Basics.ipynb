{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = tf.constant([2])\n",
    "b = tf.constant([2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = tf.add(a,b, name=\"a_add_b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#allocates session and closes automatically\n",
    "with tf.Session() as g:\n",
    "    print(g.run(c))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a1 = tf.placeholder(dtype=tf.float64)\n",
    "a2 = tf.placeholder(dtype=tf.float64)\n",
    "out = tf.multiply(a1,a2, name=\"a1_mul_b1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(out,{a1:4,a2:4})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feed_dict = {a1:5,a2:4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(out,feed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Convolution ?\n",
    "\n",
    "* g(x,y) = h(x,y)*f(x,y)\n",
    "\n",
    "* Convolution can achieve something,  that the previous two methods of manipulating images canâ€™t achieve. Those include the blurring, sharpening, edge detection, noise reduction e.t.c.\n",
    "\n",
    "### Applications in Image Processing\n",
    "* Blurring, line and edge detections\n",
    "* Sobel method, gaussian, laplacian masks are available to achieve this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and Display Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading multiple images\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "filename_queue = tf.train.string_input_producer([r'C:\\Users\\omc\\Desktop\\Deep Learning with Tensorflow\\prithvi.jpg']) #  list of files to read\n",
    "\n",
    "reader = tf.WholeFileReader()\n",
    "key, value = reader.read(filename_queue)\n",
    "my_img = tf.image.decode_png(value) # use png or jpg decoder based on your files.\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  sess.run(init_op)\n",
    "\n",
    "  # Start populating the filename queue.\n",
    "\n",
    "  coord = tf.train.Coordinator()\n",
    "  threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "  for i in range(1): #length of your filename list\n",
    "    image = my_img.eval() #here is your image Tensor :) \n",
    "\n",
    "  print(image.shape)\n",
    "  Image.fromarray(np.asarray(image)).show()    #displays image\n",
    "\n",
    "  coord.request_stop()\n",
    "  coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display image using matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "fig.add_subplot(1,2,1)\n",
    "plt.imshow(image)\n",
    "fig.add_subplot(1,2,2)\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d = tf.contrib.layers.convolution2d(\n",
    "    image_input,\n",
    "#     num_output_channels=4,     this is deprecated , use below one\n",
    "    num_outputs=4,\n",
    "    kernel_size=(1,1),          # It's only the filter height and width.\n",
    "    activation_fn=tf.nn.relu,\n",
    "    stride=(1, 1),              # Skips the stride values for image_batch and input_channels.\n",
    "    trainable=True)\n",
    "\n",
    "# It's required to initialize the variables used in convolution2d's setup.\n",
    "# sess.run(tf.initialize_all_variables())   derecated , use below function\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(conv2d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
